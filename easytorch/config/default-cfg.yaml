name: easy_experiment
data_source: some/path/to/data
image_size:
phase: train

batch_size: 4
epochs: 10
patience:

grad_accum_iters: 1
learning_rate: 0.001
gpus:
  - 0
pin_memory: False
num-workers: 4
load_limit:

output_base_dir: net_output
pretrained_path:
verbose: True
seed-all: False
seed: 1
force: False

split_ratio: [0.7, 0.15, 0.15]
use_ddp: False
multi_load: True # Parallelize data preloading if necessary. Only available when extending easytorch.dataset.ETDataset

#if use_ddp set to true, also provide
#node_rank: 0
#num_nodes: 1
#init_method: 'env://'
#dist_backend: 'nccl'
#master_addr: '127.0.0.1'
#master_port: 8998


